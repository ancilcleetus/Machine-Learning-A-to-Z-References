{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiple_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S57a5lhfiL_r"
      },
      "source": [
        "## Assumptions of Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZz_Nb9MiYUA"
      },
      "source": [
        "![Assumptions of Linear Regression](Multiple-Linear-Regression-Intuition-00.PNG)\r\n",
        "\r\n",
        "We have to check whether these assumptions hold for our dataset before going with a Linear Regression Model. But checking these for a big dataset is time consuming. Instead, you can choose to go with a Linear Regression Model and if it gives lower accuracy than other models, then we can safely conclude that Linear Regression Models cannnot be used for this particular dataset. As experimenting with different Machine Learning Models doesn't take much time, thanks to the open-source libraries, this is preferred instead of going behind the assumptions early on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm7b8JSF7Adq"
      },
      "source": [
        "## Intuition behind Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUYA2jgQ3Ri3"
      },
      "source": [
        "Linear Regression is useful when we want to predict a continuous numerical value for linear datasets (i.e. datasets with linear relationships between Features and Target Variable). Depending on the no: of features, Linear Regression can be\r\n",
        "\r\n",
        "1.   Simple Linear Regression - only a single feature\r\n",
        "2.   Multiple Linear Regression - multiple features\r\n",
        "\r\n",
        "\r\n",
        "Multiple Linear Regression involves finding the best fitting line that correlates multiple features with the target variable.\r\n",
        "![Multiple Linear Regression Equation](Multiple-Linear-Regression-Intuition-01.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOl9H2fNvvSN"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU7ZZS1r4gsN"
      },
      "source": [
        "We have a dataset containing profit data of 50 startups with vastly different proportional expenditure in R&D, Administration and Marketing. All of these are situated in one of the 3 states - New York, California or Florida. Here,\r\n",
        "\r\n",
        "\r\n",
        "*   Independent Variable/Feature = R&D Spend, Administration Spend, Marketing Spend, State\r\n",
        "*   Dependent/Target Variable = Profit\r\n",
        "\r\n",
        "The given data is to be analyzed for a Venture Capitalist Fund to find if there is any correlation between the Profit, the different amounts spent in different heads (R&D, Administration, Marketing) and the state where the Startup is situated. Since we have multiple features and the Target Variable (Profit) is a continuous variable, this is a Multiple Linear Regression problem.\r\n",
        "\r\n",
        "How this scenario fits into Multiple Linear Regression can be visualized as below:\r\n",
        "![Multiple Linear Regression for Profit Prediction: Problem](Multiple-Linear-Regression-Intuition-02.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry_BWxYUwCm1"
      },
      "source": [
        "### Dummy Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwy5ZxoLv_J1"
      },
      "source": [
        "As you can see, we encounter difficulty in mapping 'State' column into the Multiple Linear Regression Equation. We first need to convert such categorical columns into numerical values using **Dummy Variables**. One-hot Encoding can be used for achieving that.\r\n",
        "\r\n",
        "Suppose we have only two States, New York and California. Then we can apply Dummy Variables as below:\r\n",
        "![Multiple Linear Regression for Profit Prediction: Dummy Variables](Multiple-Linear-Regression-Intuition-03.PNG)\r\n",
        "\r\n",
        "Only one Dummy Column needs to be retained in this case since it represents our State info fully.\r\n",
        "\r\n",
        "$D_1 = 0 : State = California$\r\n",
        "\r\n",
        "$D_1 = 1 : State = New York$\r\n",
        "\r\n",
        "The phenomenon where one or several independent variables in a Linear Regression Model predict another is called **Multicollinearity**. If we use two dummy variables $D_1$ and $D_2$, we fall into this **Dummy Variable Trap**. As a general rule, always omit one dummy variable irrespective of the no: of dummy variables. Also, if you have two sets of dummy variables, then you need to apply the same rule to each set.\r\n",
        "\r\n",
        "![Multiple Linear Regression for Profit Prediction: Dummy Variable Trap](Multiple-Linear-Regression-Intuition-04.PNG)\r\n",
        "\r\n",
        "But, in our dataset, we have three categories for 'State' column - New York, California and Florida. Hence we need to use only two Dummy Variables and discard one. We don't need to worry about the **Dummy Variable Trap**, since it will be automatically taken cared by *LinearRegression Class*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Tts4YK9alp"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtu7lP_K-Nw4"
      },
      "source": [
        "Our requirement is to build a model that best predicts the general trend from the dataset. Hence, we need to choose the variables carefully so as not to fall into the trap of $Overfitting$ or $Underfitting$.\r\n",
        "\r\n",
        "![Multiple Linear Regression for Profit Prediction: Building a Model](Multiple-Linear-Regression-Intuition-05.PNG)\r\n",
        "\r\n",
        "The different methods for building a model are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression for Profit Prediction: Methods for Building a Model](Multiple-Linear-Regression-Intuition-06.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j08Hv_bKDBLs"
      },
      "source": [
        "#### Method 1: All-in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob2CsstnCJPM"
      },
      "source": [
        "This is applicable if you are sure that you have to use all the independent variables. This can be the scenario in the following cases:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: All-in Method](Multiple-Linear-Regression-Intuition-07.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA1dZFLxEqGX"
      },
      "source": [
        "#### Method 2: Backward Elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n99Gf_wHEy0Q"
      },
      "source": [
        "Backward Elimination Method is the approach that yields results fast. The steps for Backward Elimination Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Backward Elimination Method](Multiple-Linear-Regression-Intuition-08.PNG)\r\n",
        "\r\n",
        "**Important Note:** Each time a variable is removed, the model should be rebuilt with new coefficients and constants in Step 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at4T2dHuMdrQ"
      },
      "source": [
        "#### Method 3: Forward Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVnhH4_zMi7U"
      },
      "source": [
        "The steps for Forward Selection Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Forward Selection Method](Multiple-Linear-Regression-Intuition-09.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu6ZmuLcZcwo"
      },
      "source": [
        "#### Method 4: Bidirectional Elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd41smGoZeMf"
      },
      "source": [
        "The steps for Bidirectional Elimination Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Bidirectional Elimination Method](Multiple-Linear-Regression-Intuition-10.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWab7gW0Z7Ih"
      },
      "source": [
        "#### Method 5: Score Comparison of All Possible Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yaL_xjTZ8ET"
      },
      "source": [
        "The steps for Score Comparison Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Score Comparison Method](Multiple-Linear-Regression-Intuition-11.PNG)\r\n",
        "\r\n",
        "**Important Note:** Here, we do not try to remove any non-significant columns. But, given a dataset, we go all in for all the possible models and then find the best one. Hence, it is a very resource consuming approach and is not recommended for datasets with a large no: of columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaXr05JuXSVf"
      },
      "source": [
        "**Important Note:** Selection of most significant features and discarding of least significant features will be automatically taken cared by the *LinearRegression Class*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF5aehJrfQwj"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJR_KsIDfW_u"
      },
      "source": [
        "dataset = pd.read_csv('50_Startups.csv')\r\n",
        "X = dataset.iloc[:, :-1].values\r\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV4vkV-IMceb",
        "outputId": "1db31fb1-bdb8-4e42-a58a-4cdcf09bed94"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[165349.2 136897.8 471784.1 'New York']\n",
            " [162597.7 151377.59 443898.53 'California']\n",
            " [153441.51 101145.55 407934.54 'Florida']\n",
            " [144372.41 118671.85 383199.62 'New York']\n",
            " [142107.34 91391.77 366168.42 'Florida']\n",
            " [131876.9 99814.71 362861.36 'New York']\n",
            " [134615.46 147198.87 127716.82 'California']\n",
            " [130298.13 145530.06 323876.68 'Florida']\n",
            " [120542.52 148718.95 311613.29 'New York']\n",
            " [123334.88 108679.17 304981.62 'California']\n",
            " [101913.08 110594.11 229160.95 'Florida']\n",
            " [100671.96 91790.61 249744.55 'California']\n",
            " [93863.75 127320.38 249839.44 'Florida']\n",
            " [91992.39 135495.07 252664.93 'California']\n",
            " [119943.24 156547.42 256512.92 'Florida']\n",
            " [114523.61 122616.84 261776.23 'New York']\n",
            " [78013.11 121597.55 264346.06 'California']\n",
            " [94657.16 145077.58 282574.31 'New York']\n",
            " [91749.16 114175.79 294919.57 'Florida']\n",
            " [86419.7 153514.11 0.0 'New York']\n",
            " [76253.86 113867.3 298664.47 'California']\n",
            " [78389.47 153773.43 299737.29 'New York']\n",
            " [73994.56 122782.75 303319.26 'Florida']\n",
            " [67532.53 105751.03 304768.73 'Florida']\n",
            " [77044.01 99281.34 140574.81 'New York']\n",
            " [64664.71 139553.16 137962.62 'California']\n",
            " [75328.87 144135.98 134050.07 'Florida']\n",
            " [72107.6 127864.55 353183.81 'New York']\n",
            " [66051.52 182645.56 118148.2 'Florida']\n",
            " [65605.48 153032.06 107138.38 'New York']\n",
            " [61994.48 115641.28 91131.24 'Florida']\n",
            " [61136.38 152701.92 88218.23 'New York']\n",
            " [63408.86 129219.61 46085.25 'California']\n",
            " [55493.95 103057.49 214634.81 'Florida']\n",
            " [46426.07 157693.92 210797.67 'California']\n",
            " [46014.02 85047.44 205517.64 'New York']\n",
            " [28663.76 127056.21 201126.82 'Florida']\n",
            " [44069.95 51283.14 197029.42 'California']\n",
            " [20229.59 65947.93 185265.1 'New York']\n",
            " [38558.51 82982.09 174999.3 'California']\n",
            " [28754.33 118546.05 172795.67 'California']\n",
            " [27892.92 84710.77 164470.71 'Florida']\n",
            " [23640.93 96189.63 148001.11 'California']\n",
            " [15505.73 127382.3 35534.17 'New York']\n",
            " [22177.74 154806.14 28334.72 'California']\n",
            " [1000.23 124153.04 1903.93 'New York']\n",
            " [1315.46 115816.21 297114.46 'Florida']\n",
            " [0.0 135426.92 0.0 'California']\n",
            " [542.05 51743.15 0.0 'New York']\n",
            " [0.0 116983.8 45173.06 'California']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYD_wROl0kU_"
      },
      "source": [
        "Here we have no missing data in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DRlmPQ3taTJ"
      },
      "source": [
        "**Important Note:** If missing data acounts for less than 1% of dataset, we can discard them. But in all other cases, we have to replace missing data. Missing data can be replaced with either mean, median, most frequent data or with a constant using `SimpleImputer` from `sklearn.impute`. Other solutions include `IterativeImputer`, `KNNImputer` and `MissingIndicator`.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE5XGL2afr30"
      },
      "source": [
        "# One-hot encoding of 'State' column\r\n",
        "# Replace 'State' column with 3 new dummy columns (since we have 3 categories for 'State')\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\r\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqdGNWvQM27A",
        "outputId": "1c1547c4-0f58-441c-8e4e-cd6693900c0d"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
            " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
            " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
            " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
            " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
            " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
            " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
            " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
            " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
            " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
            " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
            " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
            " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
            " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
            " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
            " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
            " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
            " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
            " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
            " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
            " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
            " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
            " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
            " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
            " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
            " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
            " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
            " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
            " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
            " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
            " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
            " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
            " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
            " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
            " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
            " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
            " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
            " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
            " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
            " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
            " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
            " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
            " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
            " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
            " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
            " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
            " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
            " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
            " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
            " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmJIlH2mfe68"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKnUtjbqOJ0Y"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50_Jb5qgOOkQ"
      },
      "source": [
        "In Multiple Linear Regression, even if some features have higher values than others, the coefficients will compensate to put every feature on the same scale. Hence, Feature Scaling is not required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p0fHJeQYLSk",
        "outputId": "9c0dc2d9-6c75-4105-a9e1-3c57b6e4277d"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\r\n",
        "# Build Linear Regression Model\r\n",
        "regressor = LinearRegression()\r\n",
        "# Train the Linear Regression Model on Training Set\r\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kKSs4HLdPFF"
      },
      "source": [
        "y_pred = regressor.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUX1Vhsv97ZT"
      },
      "source": [
        "## Visualising the Test set results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKJZe3zSdilO"
      },
      "source": [
        "Since there are 4 features, we need a 5D plot to visualize the relationship between features and target variable. Since humans cannot visualize a 5D plot, instead we print the Predicted Profits Versus Real Profits for the Test Set as a NumPy array to visualize our Test Set Results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6OdMSyvf3y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72bfecf-9c1d-4ea1-97f7-c19392c441ce"
      },
      "source": [
        "np.set_printoptions(precision=2)\r\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[103015.2  103282.38]\n",
            " [132582.28 144259.4 ]\n",
            " [132447.74 146121.95]\n",
            " [ 71976.1   77798.83]\n",
            " [178537.48 191050.39]\n",
            " [116161.24 105008.31]\n",
            " [ 67851.69  81229.06]\n",
            " [ 98791.73  97483.56]\n",
            " [113969.44 110352.25]\n",
            " [167921.07 166187.94]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p136WrJFBLj"
      },
      "source": [
        "## Making a single prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARycFcUYnt8k"
      },
      "source": [
        "For example, the profit of a startup with R&D Spend = 160000, Administration Spend = 130000, Marketing Spend = 300000 and State = 'California'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkije4_ToeWX",
        "outputId": "9467873b-c59e-4410-e99b-922dc2dad172"
      },
      "source": [
        "print(regressor.predict([[1, 0, 0, 160000, 130000, 300000]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[181566.92]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXf9NlRFGlht"
      },
      "source": [
        "Therefore, our model predicts that the profit of a Californian startup which spent 160000 in R&D, 130000 in Administration and 300000 in Marketing is 181566.92.\n",
        "\n",
        "**Important Note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array. Simply put:\n",
        "\n",
        "$1, 0, 0, 160000, 130000, 300000 \\rightarrow \\textrm{scalars}$\n",
        "\n",
        "$[1, 0, 0, 160000, 130000, 300000] \\rightarrow \\textrm{1D array}$\n",
        "\n",
        "$[[1, 0, 0, 160000, 130000, 300000]] \\rightarrow \\textrm{2D array}$\n",
        "\n",
        "**Important Note 2:** Notice also that the \"California\" state was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the second row of the matrix of features X, \"California\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, not the last three ones, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soirA4ugKRTL"
      },
      "source": [
        "## Getting the final Multiple Linear Regression equation with the values of the coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evK0tXydpqyF",
        "outputId": "34014c6b-93ab-48a5-d6d5-fec031626f04"
      },
      "source": [
        "print(regressor.coef_)\r\n",
        "print(regressor.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8.66e+01 -8.73e+02  7.86e+02  7.73e-01  3.29e-02  3.66e-02]\n",
            "42467.52924853204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMXYYf3IKcnk"
      },
      "source": [
        "Therefore, the equation of our multiple linear regression model is:\n",
        "\n",
        "$$\\textrm{Profit} = 86.6 \\times \\textrm{Dummy State 1} - 873 \\times \\textrm{Dummy State 2} + 786 \\times \\textrm{Dummy State 3} - 0.773 \\times \\textrm{R&D Spend} + 0.0329 \\times \\textrm{Administration} + 0.0366 \\times \\textrm{Marketing Spend} + 42467.53$$\n",
        "\n",
        "**Important Note:** To get these coefficients we called the \"coef_\" and \"intercept_\" attributes from our regressor object. Attributes in Python are different than methods and usually return a simple value or an array of values."
      ]
    }
  ]
}