{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiple_linear_regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S57a5lhfiL_r"
      },
      "source": [
        "## Assumptions of Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZz_Nb9MiYUA"
      },
      "source": [
        "![Assumptions of Linear Regression](Multiple-Linear-Regression-Intuition-00.PNG)\r\n",
        "\r\n",
        "We have to first check whether these assumptions hold for our dataset before going with a Linear Regression Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm7b8JSF7Adq"
      },
      "source": [
        "## Intuition behind Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUYA2jgQ3Ri3"
      },
      "source": [
        "Linear Regression is useful when we want to predict a continuous numerical value for linear datasets (i.e. datasets with linear relationships between Features and Target Variable). Depending on the no: of features, Linear Regression can be\r\n",
        "\r\n",
        "1.   Simple Linear Regression - only a single feature\r\n",
        "2.   Multiple Linear Regression - multiple features\r\n",
        "\r\n",
        "\r\n",
        "Multiple Linear Regression involves finding the best fitting line that correlates multiple features with the target variable.\r\n",
        "![Multiple Linear Regression Equation](Multiple-Linear-Regression-Intuition-01.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOl9H2fNvvSN"
      },
      "source": [
        "### Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU7ZZS1r4gsN"
      },
      "source": [
        "Lets say we have a dataset containing profit data of 50 startups with vastly different proportional expenditure in R&D, Administration and Marketing. All of these are situated in one of the 3 states - New York, California or Florida. Here,\r\n",
        "\r\n",
        "\r\n",
        "*   Independent Variable/Feature = R&D Spend, Administration Spend, Marketing Spend, State\r\n",
        "*   Dependent/Target Variable = Profit\r\n",
        "\r\n",
        "The given data is to be analyzed for a Venture Capitalist Fund to find if there is any correlation between the Profit, the different amounts spent in different heads (R&D, Administration, Marketing) and the state where the Startup is situated. Since we have multiple features and the Target Variable (Profit) is a continuous variable, this is a Multiple Linear Regression problem.\r\n",
        "\r\n",
        "How this scenario fits into Multiple Linear Regression can be visualized as below:\r\n",
        "![Multiple Linear Regression for Profit Prediction: Problem](Multiple-Linear-Regression-Intuition-02.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry_BWxYUwCm1"
      },
      "source": [
        "### Dummy Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwy5ZxoLv_J1"
      },
      "source": [
        "As you can see, we encounter difficulty in mapping 'State' column into the Multiple Linear Regression Equation. We first need to convert such categorical columns into numerical values using $Dummy$ $Variables$. One-hot Encoding can be used for achieving that.\r\n",
        "\r\n",
        "Suppose we have only two States, New York and California. Then we can apply Dummy Variables as below:\r\n",
        "![Multiple Linear Regression for Profit Prediction: Dummy Variables](Multiple-Linear-Regression-Intuition-03.PNG)\r\n",
        "\r\n",
        "Only one Dummy Column needs to be retained in this case since it represents our State info fully.\r\n",
        "\r\n",
        "$D_1 = 0 : State = California$\r\n",
        "\r\n",
        "$D_1 = 1 : State = New York$\r\n",
        "\r\n",
        "The phenomenon where one or several independent variables in a Linear Regression Model predict another is called $Multicollinearity$. If we use two dummy variables $D_1$ and $D_2$, we fall into this $Dummy$ $Variable$ $Trap$. As a general rule, always omit one dummy variable irrespective of the no: of dummy variables. Also, if you have two sets of dummy variables, then you need to apply the same rule to each set.\r\n",
        "\r\n",
        "![Multiple Linear Regression for Profit Prediction: Dummy Variable Trap](Multiple-Linear-Regression-Intuition-04.PNG)\r\n",
        "\r\n",
        "But, in our dataset, we have three categories for 'State' column - New York, California and Florida. Hence we need to use two Dummy Variables ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Tts4YK9alp"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtu7lP_K-Nw4"
      },
      "source": [
        "Our requirement is to build a model that best predicts the general trend from the dataset. Hence, we need to choose the variables carefully so as not to fall into the trap of $Overfitting$ or $Underfitting$.\r\n",
        "\r\n",
        "![Multiple Linear Regression for Profit Prediction: Building a Model](Multiple-Linear-Regression-Intuition-05.PNG)\r\n",
        "\r\n",
        "The different methods for building a model are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression for Profit Prediction: Methods for Building a Model](Multiple-Linear-Regression-Intuition-06.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j08Hv_bKDBLs"
      },
      "source": [
        "#### Method 1: All-in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob2CsstnCJPM"
      },
      "source": [
        "This is applicable if you are sure that you have to use all the independent variables. This can be the scenario in the following cases:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: All-in Method](Multiple-Linear-Regression-Intuition-07.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA1dZFLxEqGX"
      },
      "source": [
        "#### Method 2: Backward Elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n99Gf_wHEy0Q"
      },
      "source": [
        "Backward Elimination Method is the approach that yields results fast. The steps for Backward Elimination Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Backward Elimination Method](Multiple-Linear-Regression-Intuition-08.PNG)\r\n",
        "\r\n",
        "**Important Note:** Each time a variable is removed, the model should be rebuilt with new coefficients and constants in Step 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at4T2dHuMdrQ"
      },
      "source": [
        "#### Method 3: Forward Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVnhH4_zMi7U"
      },
      "source": [
        "The steps for Forward Selection Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Forward Selection Method](Multiple-Linear-Regression-Intuition-09.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu6ZmuLcZcwo"
      },
      "source": [
        "#### Method 4: Bidirectional Elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd41smGoZeMf"
      },
      "source": [
        "The steps for Bidirectional Elimination Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Bidirectional Elimination Method](Multiple-Linear-Regression-Intuition-10.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWab7gW0Z7Ih"
      },
      "source": [
        "#### Method 5: Score Comparison of All Possible Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yaL_xjTZ8ET"
      },
      "source": [
        "The steps for Score Comparison Method are as below:\r\n",
        "\r\n",
        "![Multiple Linear Regression - Building a Model: Score Comparison Method](Multiple-Linear-Regression-Intuition-11.PNG)\r\n",
        "\r\n",
        "**Important Note:** Here, we do not try to remove any non-significant columns. But, given a dataset, we go all in for all the possible models and then find the best one. Hence, it is a very resource consuming approach and is not recommended for datasets with a large no: of columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF5aehJrfQwj"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJR_KsIDfW_u"
      },
      "source": [
        "dataset = pd.read_csv('50_Startups.csv')\r\n",
        "X = dataset.iloc[:, :-1].values\r\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE5XGL2afr30"
      },
      "source": [
        "# One-hot encoding of 'State' column\r\n",
        "# Replace 'State' column with 3 new dummy columns (since we have 3 categories for 'State')\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\r\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmJIlH2mfe68"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    }
  ]
}